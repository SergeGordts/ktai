{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9469b8-93e2-4f00-beb2-a2e980b8edc8",
   "metadata": {},
   "source": [
    "## 1. Download a local copy of an opensourced LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ac7281b-b6f4-4711-8e49-a5f4761f6a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f38d1ce-f98f-48b9-b394-77ef257369e0",
   "metadata": {},
   "source": [
    "<font size=\"2\">Prerequisites: create access token on huggingFace via profile settings and set this token in your system user variables </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5892cf8d-a808-4b82-83b6-2670baccd491",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGING_FACE_API_KEY = os.environ.get(\"HUGGING_FACE_API_KEY\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be11a5c-6f4a-405f-95d1-ad46fd34330c",
   "metadata": {},
   "source": [
    "The opensource model [**Distilbert**](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english/blob/main/README.md) has a transformer architecture, meaning it uses self-attention mechanisms to understand the relationships between words in a sentence, regardless of their distance. It is a smaller and faster version of the well-known BERT (Bidirectional Encoder Representations from Transformers) model. It was created by Hugging Face, a company known for its open-source natural language processing (NLP) tools  and libraries.  \n",
    "* DistilBERT retains the core functionalities of BERT while being more efficient in terms of parameters and computational resources.\n",
    "* It is trained on SST-2, which stands for Stanford Sentiment Treebank. SST-2 is a widely used dataset for sentiment analysis tasks in Natural Language Processing (NLP).\n",
    "* [SST-2 contains a corpus of 11,855 sentences extracted from movie review    Sentiment Labels: Each sentence is assigned a sentiment of positive or negative](https://huggingface.co/datasets/sst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "492e025f-880b-4f2d-9d86-a7fc6b13f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "filenames = [\"config.json\",\"model.safetensors\",\"pytorch_model.bin\",\"rust_model.ot\",\"tf_model.h5\",\"tokenizer_config.json\",\"vocab.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b497aa-81da-452d-af40-6c0b82792187",
   "metadata": {},
   "source": [
    "<font size=\"2\"> Donwload the model so it runs locally </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a5e34f-90d4-41f9-bb98-35594f36de5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gordts-De Laender\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\config.json\n",
      "C:\\Users\\Gordts-De Laender\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\model.safetensors\n",
      "C:\\Users\\Gordts-De Laender\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\pytorch_model.bin\n",
      "C:\\Users\\Gordts-De Laender\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\rust_model.ot\n",
      "C:\\Users\\Gordts-De Laender\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\tf_model.h5\n",
      "C:\\Users\\Gordts-De Laender\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\tokenizer_config.json\n",
      "C:\\Users\\Gordts-De Laender\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\vocab.txt\n"
     ]
    }
   ],
   "source": [
    "for filename in filenames: \n",
    "    downloaded_model_path = hf_hub_download(\n",
    "            repo_id = model_id,\n",
    "            filename = filename,\n",
    "            token = HUGGING_FACE_API_KEY\n",
    "    )\n",
    "    print (downloaded_model_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a00d26c-68a2-4897-9ac7-740fa54cdb60",
   "metadata": {},
   "source": [
    "[DistilBertForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification) is built upon the DistilBERT model and goes beyond the core DistilBERT model by adding a classification head on top of the encoder's output. This classification head takes the encoded representation of the sequence and transforms it into a probability distribution over different predefined classes. See [config.json](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english/blob/main/config.json) for the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bc98422-5467-4423-b732-1bec63c5e00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.pipelines.text_classification.TextClassificationPipeline"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, pipeline\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_id)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_id)\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=model, device=-1, tokenizer=tokenizer)\n",
    "type(classifier) #To check which pipeline the classifier inherits "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaba797-7ec4-414f-9f7a-bdccbb39953b",
   "metadata": {},
   "source": [
    "The following will print out the label and the corresponding confidence score (using the softmax function). The confidence score can be interpreted as a measure of how certain the model is about its prediction. For more info see [TextClassificationPipeline](https://huggingface.co/docs/transformers/main_classes/pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3141a6a-75dc-48ad-b7ed-ee7dd8b5a7cb",
   "metadata": {},
   "source": [
    "## 2. Prompt engineering strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c78a5ebd-8b56-49b9-9415-ae9025113358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9920676946640015}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I don't like spaghetti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f849f0c5-7764-4e47-b4de-7b9aca12a8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "with torch.no_grad(): #Disabling gradient calculation improves efficiency for inference tasks.\n",
    "    logits = model(**inputs).logits #The model processes the tokenized input and outputs a tensor named logits.logits represent the unnormalized scores (before applying softmax) for each potential sentiment class.\n",
    "\n",
    "predicted_class_id = logits.argmax().item() #This corresponds to the class with the highest predicted probability.\n",
    "model.config.id2label[predicted_class_id] #refers to the configuration of the pre-trained model see config.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c393280-f724-484c-af55-2204f192dfa4",
   "metadata": {},
   "source": [
    "##### 2.1 adding instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f879e40-9027-4ab7-a4d1-0c11167013de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prompt = \"What is the sentiment of the following text: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86adff0c-2369-472e-b42e-a068e99acc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.994526207447052}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(sentiment_prompt + \"I don't like spaghetti\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a69a34-a7a4-42c8-be06-b526f5b0ebea",
   "metadata": {},
   "source": [
    "##### 2.2 zero-shot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb2d196-6067-4bb4-a9f4-18a7e7248ef8",
   "metadata": {},
   "source": [
    "##### 2.3 few-shot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832696f4-9465-402f-a632-c2aee2bc9227",
   "metadata": {},
   "source": [
    "## 3. Stress-testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f61ef-0b2c-418b-879a-20de80c94895",
   "metadata": {},
   "source": [
    "##### 3.1 Inputs that should work well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855d8ad-8c76-4071-9677-d62fbfddf877",
   "metadata": {},
   "source": [
    "##### 3.2 Failure-case inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce911a25-ee81-438a-8de1-f848dcdbb00b",
   "metadata": {},
   "source": [
    "##### 3.3 Test for consistency (looping???)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e747cb-fc83-4ff9-b703-9e095ee5d06f",
   "metadata": {},
   "source": [
    "##### 3.4 Test for reliability (score, testing on the applied function to the model outputs in order to retrieve the scores,... )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
